{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a94875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\behlul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd16c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM, Embedding, Bidirectional, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8851828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"train.tsv.zip\", sep=\"\t\")\n",
    "test=pd.read_csv(\"test.tsv.zip\", sep=\"\t\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8ee37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156060, 4), (66292, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728a8675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId       int64\n",
       "SentenceId     int64\n",
       "Phrase        object\n",
       "Sentiment      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b75e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d06f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=train.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d97a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAEvCAYAAADlxjaNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZAElEQVR4nO3dccxd9Xkf8O9THFqaLgESDzGbzki1UlGkkMQirjJNG6xgkqrmjzQCbcWKWDwpZEunSp2zf1CTRqLS1LRIaSRUvJiuC2FpK6yG1LMIVTVpEExCSYAi3hIotkhwYwJtoyYiffbH+yO9+LzmvTY29838+UhH95zn/M65z5WuwN/3nPO71d0BAACY9SOLbgAAAFh7BAUAAGBCUAAAACYEBQAAYEJQAAAAJgQFAABgYt2iGzhRb37zm3vTpk2LbgMAAH5oPfDAA3/d3etX2vdDGxQ2bdqUAwcOLLoNAAD4oVVVTx1rn1uPAACACUEBAACYEBQAAIAJQQEAAJgQFAAAgAlBAQAAmJgrKFTVf66qh6vqa1X1mar6saq6sKruq6qlqvpsVZ05xv7o2F4a+zfNnOcjo/5YVV05U982aktVteukf0oAAOC4rBoUqmpDkv+UZEt3X5zkjCTXJPmNJJ/o7p9K8lyS68ch1yd5btQ/Mcalqi4ax/1Mkm1JfqeqzqiqM5J8MslVSS5Kcu0YCwAALMi8tx6tS3JWVa1L8uNJnklyWZLPjf17klw91reP7Yz9l1dVjfrt3f3d7v56kqUkl45lqbuf6O7vJbl9jAUAABZk1aDQ3YeS/Lckf5XlgPB8kgeSfLu7XxzDDibZMNY3JHl6HPviGP+m2fpRxxyrDgAALMg8tx6dk+W/8F+Y5J8leX2Wbx16zVXVzqo6UFUHDh8+vIgWAADgtLBujjH/JsnXu/twklTVHyZ5V5Kzq2rduGqwMcmhMf5QkguSHBy3Kr0xybdm6i+ZPeZY9Zfp7luS3JIkW7Zs6Tl6h4XatOvzi26BE/DkTe9ZdAsAsHDzPKPwV0m2VtWPj2cNLk/ySJJ7krx3jNmR5M6xvndsZ+z/Ynf3qF8zZkW6MMnmJF9Kcn+SzWMWpTOz/MDz3lf/0QAAgBO16hWF7r6vqj6X5MtJXkzylSz/Vf/zSW6vql8ftVvHIbcm+b2qWkpyJMv/8E93P1xVd2Q5ZLyY5Ibu/n6SVNWHkuzL8oxKu7v74ZP3EQEAgOM1z61H6e4bk9x4VPmJLM9YdPTYv0/yi8c4z8eTfHyF+l1J7pqnFwAA4NTzy8wAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAxKpBoareUlUPziwvVNUvV9W5VbW/qh4fr+eM8VVVN1fVUlU9VFVvnznXjjH+8araMVN/R1V9dRxzc1XVqfm4AADAPFYNCt39WHdf0t2XJHlHku8k+aMku5Lc3d2bk9w9tpPkqiSbx7IzyaeSpKrOTXJjkncmuTTJjS+FizHmAzPHbTsZHw4AADgxx3vr0eVJ/rK7n0qyPcmeUd+T5Oqxvj3Jbb3s3iRnV9X5Sa5Msr+7j3T3c0n2J9k29r2hu+/t7k5y28y5AACABTjeoHBNks+M9fO6+5mx/o0k5431DUmenjnm4Ki9Uv3gCnUAAGBB5g4KVXVmkl9I8r+O3jeuBPRJ7OtYPeysqgNVdeDw4cOn+u0AAOC0dTxXFK5K8uXu/ubY/ua4bSjj9dlRP5TkgpnjNo7aK9U3rlCf6O5buntLd29Zv379cbQOAAAcj+MJCtfmH287SpK9SV6auWhHkjtn6teN2Y+2Jnl+3KK0L8kVVXXOeIj5iiT7xr4XqmrrmO3ouplzAQAAC7BunkFV9fokP5fkP8yUb0pyR1Vdn+SpJO8b9buSvDvJUpZnSHp/knT3kar6WJL7x7iPdveRsf7BJJ9OclaSL4wFAABYkLmCQnf/XZI3HVX7VpZnQTp6bCe54Rjn2Z1k9wr1A0kunqcXAADg1PPLzAAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMCEoAAAAEzMFRSq6uyq+lxV/UVVPVpVP1tV51bV/qp6fLyeM8ZWVd1cVUtV9VBVvX3mPDvG+MerasdM/R1V9dVxzM1VVSf/owIAAPOa94rCbyf5k+7+6SRvTfJokl1J7u7uzUnuHttJclWSzWPZmeRTSVJV5ya5Mck7k1ya5MaXwsUY84GZ47a9uo8FAAC8GqsGhap6Y5J/meTWJOnu73X3t5NsT7JnDNuT5Oqxvj3Jbb3s3iRnV9X5Sa5Msr+7j3T3c0n2J9k29r2hu+/t7k5y28y5AACABZjnisKFSQ4n+e9V9ZWq+t2qen2S87r7mTHmG0nOG+sbkjw9c/zBUXul+sEV6gAAwILMExTWJXl7kk9199uS/F3+8TajJMm4EtAnv72Xq6qdVXWgqg4cPnz4VL8dAACctuYJCgeTHOzu+8b257IcHL45bhvKeH127D+U5IKZ4zeO2ivVN65Qn+juW7p7S3dvWb9+/RytAwAAJ2LVoNDd30jydFW9ZZQuT/JIkr1JXpq5aEeSO8f63iTXjdmPtiZ5ftyitC/JFVV1zniI+Yok+8a+F6pq65jt6LqZcwEAAAuwbs5x/zHJ71fVmUmeSPL+LIeMO6rq+iRPJXnfGHtXkncnWUrynTE23X2kqj6W5P4x7qPdfWSsfzDJp5OcleQLYwEAABZkrqDQ3Q8m2bLCrstXGNtJbjjGeXYn2b1C/UCSi+fpBQAAOPX8MjMAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwMVdQqKonq+qrVfVgVR0YtXOran9VPT5ezxn1qqqbq2qpqh6qqrfPnGfHGP94Ve2Yqb9jnH9pHFsn+4MCAADzO54rCv+6uy/p7i1je1eSu7t7c5K7x3aSXJVk81h2JvlUshwsktyY5J1JLk1y40vhYoz5wMxx2074EwEAAK/aq7n1aHuSPWN9T5KrZ+q39bJ7k5xdVecnuTLJ/u4+0t3PJdmfZNvY94buvre7O8ltM+cCAAAWYN6g0En+d1U9UFU7R+287n5mrH8jyXljfUOSp2eOPThqr1Q/uEIdAABYkHVzjvsX3X2oqv5pkv1V9RezO7u7q6pPfnsvN0LKziT5yZ/8yVP9dgAAcNqa64pCdx8ar88m+aMsP2PwzXHbUMbrs2P4oSQXzBy+cdReqb5xhfpKfdzS3Vu6e8v69evnaR0AADgBqwaFqnp9Vf2Tl9aTXJHka0n2Jnlp5qIdSe4c63uTXDdmP9qa5Plxi9K+JFdU1TnjIeYrkuwb+16oqq1jtqPrZs4FAAAswDy3Hp2X5I/GjKXrkvzP7v6Tqro/yR1VdX2Sp5K8b4y/K8m7kywl+U6S9ydJdx+pqo8luX+M+2h3HxnrH0zy6SRnJfnCWAAAgAVZNSh09xNJ3rpC/VtJLl+h3kluOMa5difZvUL9QJKL5+gXAAB4DfhlZgAAYEJQAAAAJgQFAABgQlAAAAAmBAUAAGBCUAAAACYEBQAAYEJQAAAAJgQFAABgQlAAAAAmBAUAAGBCUAAAACYEBQAAYEJQAAAAJgQFAABgQlAAAAAmBAUAAGBCUAAAACYEBQAAYEJQAAAAJgQFAABgQlAAAAAmBAUAAGBCUAAAACbmDgpVdUZVfaWq/nhsX1hV91XVUlV9tqrOHPUfHdtLY/+mmXN8ZNQfq6orZ+rbRm2pqnadxM8HAACcgOO5ovDhJI/ObP9Gkk90908leS7J9aN+fZLnRv0TY1yq6qIk1yT5mSTbkvzOCB9nJPlkkquSXJTk2jEWAABYkLmCQlVtTPKeJL87tivJZUk+N4bsSXL1WN8+tjP2Xz7Gb09ye3d/t7u/nmQpyaVjWeruJ7r7e0luH2MBAIAFmfeKwm8l+dUk/zC235Tk29394tg+mGTDWN+Q5OkkGfufH+N/UD/qmGPVAQCABVk1KFTVzyd5trsfeA36Wa2XnVV1oKoOHD58eNHtAADA/7fmuaLwriS/UFVPZvm2oMuS/HaSs6tq3RizMcmhsX4oyQVJMva/Mcm3ZutHHXOs+kR339LdW7p7y/r16+doHQAAOBGrBoXu/kh3b+zuTVl+GPmL3f1vk9yT5L1j2I4kd471vWM7Y/8Xu7tH/ZoxK9KFSTYn+VKS+5NsHrMonTneY+9J+XQAAMAJWbf6kGP6L0lur6pfT/KVJLeO+q1Jfq+qlpIcyfI//NPdD1fVHUkeSfJikhu6+/tJUlUfSrIvyRlJdnf3w6+iLwAA4FU6rqDQ3X+a5E/H+hNZnrHo6DF/n+QXj3H8x5N8fIX6XUnuOp5eAACAU8cvMwMAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADCxbtENAJzONu36/KJb4AQ8edN7Ft0CwCnnigIAADAhKAAAABOCAgAAMCEoAAAAE6sGhar6sar6UlX9eVU9XFW/NuoXVtV9VbVUVZ+tqjNH/UfH9tLYv2nmXB8Z9ceq6sqZ+rZRW6qqXafgcwIAAMdhnisK301yWXe/NcklSbZV1dYkv5HkE939U0meS3L9GH99kudG/RNjXKrqoiTXJPmZJNuS/E5VnVFVZyT5ZJKrklyU5NoxFgAAWJBVg0Iv+9ux+bqxdJLLknxu1PckuXqsbx/bGfsvr6oa9du7+7vd/fUkS0kuHctSdz/R3d9LcvsYCwAALMhczyiMv/w/mOTZJPuT/GWSb3f3i2PIwSQbxvqGJE8nydj/fJI3zdaPOuZYdQAAYEHmCgrd/f3uviTJxixfAfjpU9nUsVTVzqo6UFUHDh8+vIgWAADgtHBcsx5197eT3JPkZ5OcXVUv/bLzxiSHxvqhJBckydj/xiTfmq0fdcyx6iu9/y3dvaW7t6xfv/54WgcAAI7DPLMera+qs8f6WUl+LsmjWQ4M7x3DdiS5c6zvHdsZ+7/Y3T3q14xZkS5MsjnJl5Lcn2TzmEXpzCw/8Lz3JHw2AADgBK1bfUjOT7JnzE70I0nu6O4/rqpHktxeVb+e5CtJbh3jb03ye1W1lORIlv/hn+5+uKruSPJIkheT3NDd30+SqvpQkn1Jzkiyu7sfPmmfEAAAOG6rBoXufijJ21aoP5Hl5xWOrv99kl88xrk+nuTjK9TvSnLXHP0CAACvAb/MDAAATAgKAADAhKAAAABMCAoAAMDEPLMeAQALtGnX5xfdAifgyZves+gW4FVxRQEAAJgQFAAAgAlBAQAAmBAUAACACUEBAACYEBQAAIAJQQEAAJgQFAAAgAlBAQAAmBAUAACACUEBAACYEBQAAIAJQQEAAJgQFAAAgAlBAQAAmBAUAACACUEBAACYEBQAAIAJQQEAAJhYNShU1QVVdU9VPVJVD1fVh0f93KraX1WPj9dzRr2q6uaqWqqqh6rq7TPn2jHGP15VO2bq76iqr45jbq6qOhUfFgAAmM88VxReTPIr3X1Rkq1Jbqiqi5LsSnJ3d29OcvfYTpKrkmwey84kn0qWg0WSG5O8M8mlSW58KVyMMR+YOW7bq/9oAADAiVo1KHT3M9395bH+N0keTbIhyfYke8awPUmuHuvbk9zWy+5NcnZVnZ/kyiT7u/tIdz+XZH+SbWPfG7r73u7uJLfNnAsAAFiA43pGoao2JXlbkvuSnNfdz4xd30hy3ljfkOTpmcMOjtor1Q+uUAcAABZk7qBQVT+R5A+S/HJ3vzC7b1wJ6JPc20o97KyqA1V14PDhw6f67QAA4LQ1V1CoqtdlOST8fnf/4Sh/c9w2lPH67KgfSnLBzOEbR+2V6htXqE909y3dvaW7t6xfv36e1gEAgBMwz6xHleTWJI9292/O7Nqb5KWZi3YkuXOmft2Y/WhrkufHLUr7klxRVeeMh5ivSLJv7HuhqraO97pu5lwAAMACrJtjzLuS/FKSr1bVg6P2X5PclOSOqro+yVNJ3jf23ZXk3UmWknwnyfuTpLuPVNXHktw/xn20u4+M9Q8m+XSSs5J8YSwAAMCCrBoUuvv/JDnW7xpcvsL4TnLDMc61O8nuFeoHkly8Wi8AAMBrwy8zAwAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATggIAADAhKAAAABOrBoWq2l1Vz1bV12Zq51bV/qp6fLyeM+pVVTdX1VJVPVRVb585ZscY/3hV7Zipv6OqvjqOubmq6mR/SAAA4PjMc0Xh00m2HVXbleTu7t6c5O6xnSRXJdk8lp1JPpUsB4skNyZ5Z5JLk9z4UrgYYz4wc9zR7wUAALzGVg0K3f1nSY4cVd6eZM9Y35Pk6pn6bb3s3iRnV9X5Sa5Msr+7j3T3c0n2J9k29r2hu+/t7k5y28y5AACABTnRZxTO6+5nxvo3kpw31jckeXpm3MFRe6X6wRXqAADAAr3qh5nHlYA+Cb2sqqp2VtWBqjpw+PDh1+ItAQDgtHSiQeGb47ahjNdnR/1Qkgtmxm0ctVeqb1yhvqLuvqW7t3T3lvXr159g6wAAwGpONCjsTfLSzEU7ktw5U79uzH60Ncnz4xalfUmuqKpzxkPMVyTZN/a9UFVbx2xH182cCwAAWJB1qw2oqs8k+VdJ3lxVB7M8e9FNSe6oquuTPJXkfWP4XUnenWQpyXeSvD9JuvtIVX0syf1j3Ee7+6UHpD+Y5ZmVzkryhbEAADCnTbs+v+gWOAFP3vSeRbfwilYNCt197TF2Xb7C2E5ywzHOszvJ7hXqB5JcvFofAADAa8cvMwMAABOCAgAAMCEoAAAAE4ICAAAwISgAAAATq856xLGZiuyHz1qfhgwAYK1wRQEAAJgQFAAAgAlBAQAAmBAUAACACUEBAACYEBQAAIAJQQEAAJgQFAAAgAlBAQAAmBAUAACACUEBAACYEBQAAIAJQQEAAJgQFAAAgAlBAQAAmBAUAACACUEBAACYEBQAAICJNRMUqmpbVT1WVUtVtWvR/QAAwOlsTQSFqjojySeTXJXkoiTXVtVFi+0KAABOX2siKCS5NMlSdz/R3d9LcnuS7QvuCQAATltrJShsSPL0zPbBUQMAABagunvRPaSq3ptkW3f/+7H9S0ne2d0fOmrcziQ7x+Zbkjz2mjZ6enlzkr9edBOsab4jrMZ3hHn4nrAa35FT65939/qVdqx7rTs5hkNJLpjZ3jhqL9PdtyS55bVq6nRWVQe6e8ui+2Dt8h1hNb4jzMP3hNX4jizOWrn16P4km6vqwqo6M8k1SfYuuCcAADhtrYkrCt39YlV9KMm+JGck2d3dDy+4LQAAOG2tiaCQJN19V5K7Ft0HP+AWL1bjO8JqfEeYh+8Jq/EdWZA18TAzAACwtqyVZxQAAIA1RFDgZapqW1U9VlVLVbVr0f2w9lTV7qp6tqq+tuheWJuq6oKquqeqHqmqh6vqw4vuibWlqn6sqr5UVX8+viO/tuieWJuq6oyq+kpV/fGiezkdCQr8QFWdkeSTSa5KclGSa6vqosV2xRr06STbFt0Ea9qLSX6luy9KsjXJDf5bwlG+m+Sy7n5rkkuSbKuqrYttiTXqw0keXXQTpytBgVmXJlnq7ie6+3tJbk+yfcE9scZ0958lObLoPli7uvuZ7v7yWP+bLP9PfsNiu2It6WV/OzZfNxYPTfIyVbUxyXuS/O6iezldCQrM2pDk6Zntg/E/d+BVqKpNSd6W5L4Ft8IaM24peTDJs0n2d7fvCEf7rSS/muQfFtzHaUtQAOCUqKqfSPIHSX65u19YdD+sLd39/e6+JMnGJJdW1cULbok1pKp+Psmz3f3Aons5nQkKzDqU5IKZ7Y2jBnBcqup1WQ4Jv9/df7jofli7uvvbSe6JZ594uXcl+YWqejLLt0JfVlX/Y7EtnX4EBWbdn2RzVV1YVWcmuSbJ3gX3BPyQqapKcmuSR7v7NxfdD2tPVa2vqrPH+llJfi7JXyy0KdaU7v5Id2/s7k1Z/vfIF7v73y24rdOOoMAPdPeLST6UZF+WHz68o7sfXmxXrDVV9Zkk/zfJW6rqYFVdv+ieWHPeleSXsvwXwAfH8u5FN8Wacn6Se6rqoSz/kWp/d5v+EtYYv8wMAABMuKIAAABMCAoAAMCEoAAAAEwICgAAwISgAAAATAgKAADAhKAAAABMCAoAAMDE/wPXYHkIQU0pqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "plt.bar(height=train.Sentiment.value_counts(), x=train.Sentiment.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01001f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b71588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kolay metin temizleme ve işleme için İfadeyi bir listeye alın\n",
    "raw_phrases = train.Phrase.values\n",
    "raw_phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88555f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normal ifadeler kullanarak IP adreslerini ve URL'leri kaldırın\n",
    "phrases_ip_remove = [re.sub(r'((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', text) for text in raw_phrases]\n",
    "phrases_ip_remove[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52f91f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander  some of which occasionally amuses but none of which amounts to much of a story '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normal ifadeler kullanarak özel karakterleri kaldırın\n",
    "phrases_spl_remove = [re.sub('[^A-Za-z \\']+', '', text) for text in phrases_ip_remove]\n",
    "phrases_spl_remove[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701f762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a series of escapades demonstrating the adage that what is good for the goose is also good for the gander  some of which occasionally amuses but none of which amounts to much of a story '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case normalize\n",
    "phrases_lower=[text.lower() for text in phrases_spl_remove]\n",
    "phrases_lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3bd3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'escapades',\n",
       " 'demonstrating',\n",
       " 'the',\n",
       " 'adage',\n",
       " 'that',\n",
       " 'what',\n",
       " 'is',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'goose',\n",
       " 'is',\n",
       " 'also',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'gander',\n",
       " 'some',\n",
       " 'of',\n",
       " 'which',\n",
       " 'occasionally',\n",
       " 'amuses',\n",
       " 'but',\n",
       " 'none',\n",
       " 'of',\n",
       " 'which',\n",
       " 'amounts',\n",
       " 'to',\n",
       " 'much',\n",
       " 'of',\n",
       " 'a',\n",
       " 'story']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_word_tok0=[word_tokenize(text) for text in phrases_lower]\n",
    "phrases_word_tok0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2fda455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'escapades',\n",
       " 'demonstrating',\n",
       " 'the',\n",
       " 'adage',\n",
       " 'that',\n",
       " 'what',\n",
       " 'is',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'goose',\n",
       " 'is',\n",
       " 'also',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'gander',\n",
       " 'some',\n",
       " 'of',\n",
       " 'which',\n",
       " 'occasionally',\n",
       " 'amuses',\n",
       " 'but',\n",
       " 'none',\n",
       " 'of',\n",
       " 'which',\n",
       " 'amounts',\n",
       " 'to',\n",
       " 'much',\n",
       " 'of',\n",
       " 'a',\n",
       " 'story']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_word_tok=[]\n",
    "for words in phrases_word_tok0:\n",
    "    phrases_word_tok.append([word for word in words if word not in punctuation])\n",
    "phrases_word_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8043cab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a series of escapades demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amounts to much of a story'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_phrases_train=[]\n",
    "for text in phrases_word_tok:\n",
    "    cleaned_phrases_train.append(\" \".join(word for word in text))\n",
    "cleaned_phrases_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec3e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d9e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(cleaned_phrases_train, labels, test_size=0.10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1183c46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140454, 200), (140454,), (15606, 200), (15606,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=train.Sentiment.values\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_train=pad_sequences(sequences, maxlen=200)\n",
    "sequences = tokenizer.texts_to_sequences(x_val)\n",
    "x_val=pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164183cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test verileri için Ön İşleme İşlevi\n",
    "def Preprocess(test):\n",
    "        \n",
    "    #Kolay metin temizleme ve işleme için İfadeyi bir listeye alın\n",
    "    raw_phrases = test.Phrase.values\n",
    "    \n",
    "    #Normal ifadeler kullanarak URL'leri kaldırın\n",
    "    phrases_ip_remove = [re.sub(r'((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', text) for text in raw_phrases]\n",
    "    \n",
    "       \n",
    "    #Normal ifadeler kullanarak özel karakterleri kaldırın\n",
    "    phrases_spl_remove = [re.sub('[^A-Za-z \\']+', '', text) for text in phrases_ip_remove]\n",
    "    phrases_spl_remove[0]\n",
    "\n",
    "    #case normalize \n",
    "    phrases_lower=[text.lower() for text in phrases_spl_remove]\n",
    "    \n",
    "    phrases_word_tok0=[word_tokenize(text) for text in phrases_lower]\n",
    "    \n",
    "    phrases_word_tok=[]\n",
    "    for words in phrases_word_tok0:\n",
    "        phrases_word_tok.append([word for word in words if word not in punctuation])\n",
    "    phrases_word_tok[0]\n",
    "    \n",
    "    cleaned_phrases=[]\n",
    "    for text in phrases_word_tok:\n",
    "        cleaned_phrases.append(\" \".join(word for word in text))\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(cleaned_phrases)\n",
    "    test_trans=pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "    return test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b0b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27906308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 500)          10000000  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              289280    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2064      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,291,829\n",
      "Trainable params: 10,291,765\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(20000, 500, input_length=x_train.shape[1])),\n",
    "model.add(Bidirectional(LSTM(64,  activation='relu'))),\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb6dde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12584497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "486/486 [==============================] - 866s 2s/step - loss: 1.2960 - accuracy: 0.5048 - val_loss: 1.0334 - val_accuracy: 0.6073\n",
      "Epoch 2/12\n",
      "486/486 [==============================] - 997s 2s/step - loss: 0.9156 - accuracy: 0.6337 - val_loss: 0.8731 - val_accuracy: 0.6439\n",
      "Epoch 3/12\n",
      "486/486 [==============================] - 1042s 2s/step - loss: 0.8126 - accuracy: 0.6703 - val_loss: 0.8268 - val_accuracy: 0.6594\n",
      "Epoch 4/12\n",
      "486/486 [==============================] - 1031s 2s/step - loss: 0.7543 - accuracy: 0.6913 - val_loss: 1.2016 - val_accuracy: 0.5197\n",
      "Epoch 5/12\n",
      "486/486 [==============================] - 1033s 2s/step - loss: 0.7030 - accuracy: 0.7129 - val_loss: 0.8416 - val_accuracy: 0.6563\n",
      "Epoch 6/12\n",
      "486/486 [==============================] - 1039s 2s/step - loss: 0.6666 - accuracy: 0.7255 - val_loss: 0.8579 - val_accuracy: 0.6673\n",
      "Epoch 7/12\n",
      "486/486 [==============================] - 1067s 2s/step - loss: 0.6391 - accuracy: 0.7371 - val_loss: 1.4348 - val_accuracy: 0.5061\n",
      "Epoch 8/12\n",
      "486/486 [==============================] - 1307s 3s/step - loss: 0.6088 - accuracy: 0.7483 - val_loss: 1.4776 - val_accuracy: 0.5061\n",
      "Epoch 9/12\n",
      "486/486 [==============================] - 1257s 3s/step - loss: 0.5837 - accuracy: 0.7579 - val_loss: 1.4980 - val_accuracy: 0.5061\n",
      "Epoch 10/12\n",
      "486/486 [==============================] - 1261s 3s/step - loss: 0.5604 - accuracy: 0.7677 - val_loss: 1.5177 - val_accuracy: 0.5061\n",
      "Epoch 11/12\n",
      "224/486 [============>.................] - ETA: 11:12 - loss: 0.5142 - accuracy: 0.7889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m289\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, to_categorical(y_train), epochs=5, batch_size=289, validation_data=(x_val, to_categorical(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ca8d9e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy vs Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b92daf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 116s 236ms/step - loss: 1.5869 - accuracy: 0.5061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5868918895721436, 0.5060874223709106]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, to_categorical(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cb11185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 338s 163ms/step\n"
     ]
    }
   ],
   "source": [
    "test_data = Preprocess(test)\n",
    "test['Sentiment'] = np.argmax(model.predict(test_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a1eb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:,['PhraseId','Sentiment']].to_csv(\"./Submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ad0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
